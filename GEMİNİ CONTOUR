import cv2
import numpy as np
import os

def analyze_sem_images(image_directory, num_images=25, threshold_value=50):
    """
    Analyzes a series of grayscale SEM images in a specified directory.

    Args:
        image_directory (str): The path to the directory containing the images.
        num_images (int): The number of images to analyze (assumes 1.png to num_images.png).
        threshold_value (int): The threshold value for binary inversion.

    Returns:
        None: Prints the analysis results for each image and overall statistics.
    """

    total_particles_all_images = 0
    total_area_all_images = 0
    total_image_area_all = 0
    images_processed = 0

    print("--- SEM Image Analysis ---")
    print(f"Directory: {image_directory}")
    print(f"Threshold Value: {threshold_value}")
    print("-" * 30)

    for i in range(1, num_images + 1):
        image_path = os.path.join(image_directory, f"{i}.png")

        # Check if the file exists
        if not os.path.exists(image_path):
            print(f"Warning: Image {image_path} not found. Skipping.")
            continue

        # 1. Read the grayscale image
        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

        if img is None:
            print(f"Error: Could not read image {image_path}. Skipping.")
            continue

        images_processed += 1
        height, width = img.shape
        total_image_area = height * width

        # 2. Apply invert binary thresholding
        _, thresh = cv2.threshold(img, threshold_value, 255, cv2.THRESH_BINARY_INV)

        # 3. Find external contours
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # 4. Calculate metrics
        num_particles = len(contours)
        total_area_particles = 0
        for cnt in contours:
            total_area_particles += cv2.contourArea(cnt)

        average_size = total_area_particles / num_particles if num_particles > 0 else 0
        area_percent = (total_area_particles / total_image_area) * 100

        # Update overall statistics
        total_particles_all_images += num_particles
        total_area_all_images += total_area_particles
        total_image_area_all += total_image_area

        # 5. Print results for the current image
        print(f"--- Image: {i}.png ---")
        print(f"  Number of Particles: {num_particles}")
        print(f"  Total Particle Area (px²): {total_area_particles:.2f}")
        print(f"  Average Particle Size (px²): {average_size:.2f}")
        print(f"  Area %: {area_percent:.2f}%")
        print("-" * 30)


    # Print Overall Statistics
    if images_processed > 0:
        overall_average_particles = total_particles_all_images / images_processed
        overall_average_area = total_area_all_images / images_processed
        overall_average_size = total_area_all_images / total_particles_all_images if total_particles_all_images > 0 else 0
        overall_area_percent = (total_area_all_images / total_image_area_all) * 100

        print("\n--- Overall Statistics ---")
        print(f"  Images Processed: {images_processed}")
        print(f"  Total Particles Found: {total_particles_all_images}")
        print(f"  Average Particles per Image: {overall_average_particles:.2f}")
        print(f"  Average Total Area per Image (px²): {overall_average_area:.2f}")
        print(f"  Overall Average Particle Size (px²): {overall_average_size:.2f}")
        print(f"  Overall Area %: {overall_area_percent:.2f}%")
        print("=" * 30)
    else:
        print("No images were processed. Please check the directory and image names.")


# --- How to use ---
# 1. Make sure you have OpenCV installed: pip install opencv-python numpy
# 2. Place your 25 grayscale images (1.png, 2.png, ..., 25.png) in a directory.
# 3. Change 'your_image_directory_path' to the actual path of your directory.
#    If using Google Colab and images are in /content/, use '/content/'.

# Example usage (replace with your actual path):
image_directory = '/content/'
analyze_sem_images(image_directory)
